{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "productive-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import gzip\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import pygeohash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "extreme-elephant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directories\n",
    "current_dir = Path(os.getcwd()).absolute()\n",
    "results_dir = current_dir.joinpath('results')\n",
    "\n",
    "if results_dir.exists():\n",
    "    shutil.rmtree(results_dir)\n",
    "\n",
    "results_dir.mkdir(parents = True, exist_ok = True)\n",
    "src_data_path = '/home/jovyan/dsc650/data/processed/openflights/routes.jsonl.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "forty-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read routes file\n",
    "def read_jsonl_data():\n",
    "    with gzip.open(src_data_path, 'rb') as f:\n",
    "        records = [json.loads(line) for line in f.readlines()]\n",
    "        \n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pacific-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten record\n",
    "def flatten_record(record):\n",
    "    flat_record = dict()\n",
    "    \n",
    "    for key, value in record.items():\n",
    "        if key in ['airline', 'src_airport', 'dst_airport']:\n",
    "            if isinstance(value, dict):\n",
    "                for child_key, child_value in value.items():\n",
    "                    flat_key = '{}_{}'.format(key, child_key)\n",
    "                    flat_record[flat_key] = child_value\n",
    "        else:\n",
    "            flat_record[key] = value\n",
    "    \n",
    "    return flat_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "available-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flattened_dataset():\n",
    "    records = read_jsonl_data()\n",
    "    \n",
    "    parquet_path = results_dir.joinpath('routes-flattened.parquet')\n",
    "    \n",
    "    return pd.DataFrame.from_records([flatten_record(record) for record in records])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-minneapolis",
   "metadata": {},
   "source": [
    "## Assignment 7.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-review",
   "metadata": {},
   "source": [
    "In this part of the assignment, you will partition a dataset using different strategies. You will use the routes.parquet dataset you created in a previous assignment. For this dataset, the key for each route will be the three-letter source airport code concatenated with the three-letter destination airport code and the two-letter airline. For instance, a route from Omaha Eppley Airfield (OMA) to Denver International Airport (DEN) on American Airlines (AA) has a key of OMADENAA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-cuisine",
   "metadata": {},
   "source": [
    "### a."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-leeds",
   "metadata": {},
   "source": [
    "We will create 16 partitions so that we can compare it to the partitions we create from hashed keys in the next part of the assignment. The partitions are determined by the first letter of the composite key using the following partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "patient-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load parquet dataset\n",
    "df = create_flattened_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "multiple-victorian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_airport_iata</th>\n",
       "      <th>dst_airport_iata</th>\n",
       "      <th>airline_iata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AER</td>\n",
       "      <td>KZN</td>\n",
       "      <td>2B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASF</td>\n",
       "      <td>KZN</td>\n",
       "      <td>2B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASF</td>\n",
       "      <td>MRV</td>\n",
       "      <td>2B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CEK</td>\n",
       "      <td>KZN</td>\n",
       "      <td>2B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CEK</td>\n",
       "      <td>OVB</td>\n",
       "      <td>2B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  src_airport_iata dst_airport_iata airline_iata\n",
       "0              AER              KZN           2B\n",
       "1              ASF              KZN           2B\n",
       "2              ASF              MRV           2B\n",
       "3              CEK              KZN           2B\n",
       "4              CEK              OVB           2B"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['src_airport_iata', 'dst_airport_iata', 'airline_iata']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "female-telling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_airport_iata</th>\n",
       "      <th>dst_airport_iata</th>\n",
       "      <th>airline_iata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67658</th>\n",
       "      <td>WYA</td>\n",
       "      <td>ADL</td>\n",
       "      <td>ZL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67659</th>\n",
       "      <td>DME</td>\n",
       "      <td>FRU</td>\n",
       "      <td>ZM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67660</th>\n",
       "      <td>FRU</td>\n",
       "      <td>DME</td>\n",
       "      <td>ZM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67661</th>\n",
       "      <td>FRU</td>\n",
       "      <td>OSS</td>\n",
       "      <td>ZM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67662</th>\n",
       "      <td>OSS</td>\n",
       "      <td>FRU</td>\n",
       "      <td>ZM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      src_airport_iata dst_airport_iata airline_iata\n",
       "67658              WYA              ADL           ZL\n",
       "67659              DME              FRU           ZM\n",
       "67660              FRU              DME           ZM\n",
       "67661              FRU              OSS           ZM\n",
       "67662              OSS              FRU           ZM"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['src_airport_iata', 'dst_airport_iata', 'airline_iata']].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "paperback-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign keys\n",
    "df['key'] = df['src_airport_iata'].astype(str) + df['dst_airport_iata'].astype(str) + df['airline_iata'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "partial-africa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    AERKZN2B\n",
       "1    ASFKZN2B\n",
       "2    ASFMRV2B\n",
       "3    CEKKZN2B\n",
       "4    CEKOVB2B\n",
       "Name: key, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['key'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "meaning-history",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67658    WYAADLZL\n",
       "67659    DMEFRUZM\n",
       "67660    FRUDMEZM\n",
       "67661    FRUOSSZM\n",
       "67662    OSSFRUZM\n",
       "Name: key, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['key'].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "toxic-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define partitions\n",
    "partitions = (\n",
    "    ('A', 'A'), ('B', 'B'), ('C', 'D'), ('E', 'F'),\n",
    "    ('G', 'H'), ('I', 'J'), ('K', 'L'), ('M', 'M'),\n",
    "    ('N', 'N'), ('O', 'P'), ('Q', 'R'), ('S', 'T'),\n",
    "    ('U', 'U'), ('V', 'V'), ('W', 'X'), ('Y', 'Z')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-metro",
   "metadata": {},
   "source": [
    "Results directions should be set up like this:\n",
    "\n",
    "kv<br />\n",
    "├── kv_key=A<br />\n",
    "├── kv_key=B<br />\n",
    "├── kv_key=C-D<br />\n",
    "├── kv_key=E-F<br />\n",
    "├── kv_key=G-H<br />\n",
    "├── kv_key=I-J<br />\n",
    "├── kv_key=K-L<br />\n",
    "├── kv_key=M<br />\n",
    "├── kv_key=N<br />\n",
    "├── kv_key=O-P<br />\n",
    "├── kv_key=Q-R<br />\n",
    "├── kv_key=S-T<br />\n",
    "├── kv_key=U<br />\n",
    "├── kv_key=V<br />\n",
    "├── kv_key=W-X<br />\n",
    "└── kv_key=Y-Z<br />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "normal-middle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('A', 'A'): 'A', ('B', 'B'): 'B', ('C', 'D'): 'C-D', ('E', 'F'): 'E-F', ('G', 'H'): 'G-H', ('I', 'J'): 'I-J', ('K', 'L'): 'K-L', ('M', 'M'): 'M', ('N', 'N'): 'N', ('O', 'P'): 'O-P', ('Q', 'R'): 'Q-R', ('S', 'T'): 'S-T', ('U', 'U'): 'U', ('V', 'V'): 'V', ('W', 'X'): 'W-X', ('Y', 'Z'): 'Y-Z'}\n"
     ]
    }
   ],
   "source": [
    "# Set up dictionary of partitions and kv_keys\n",
    "partition_dict = {}\n",
    "\n",
    "for i in partitions:\n",
    "    if i[0] == i[1]:\n",
    "        partition_dict[i] = i[0]\n",
    "    else:\n",
    "        partition_dict[i] = i[0] + '-' + i[1]\n",
    "        \n",
    "print(partition_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "female-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate kv_key from key\n",
    "def kv_key_gen(data_key):\n",
    "    for key, val in partition_dict.items():\n",
    "        if data_key[0] == key[0] or data_key[0] == key[1]:\n",
    "            return val\n",
    "        \n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "written-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add kv_key column to df\n",
    "df['kv_key'] = df['key'].apply(kv_key_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "transparent-choir",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kv_key</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>AERKZN2B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>ASFKZN2B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>ASFMRV2B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C-D</td>\n",
       "      <td>CEKKZN2B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C-D</td>\n",
       "      <td>CEKOVB2B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kv_key       key\n",
       "0      A  AERKZN2B\n",
       "1      A  ASFKZN2B\n",
       "2      A  ASFMRV2B\n",
       "3    C-D  CEKKZN2B\n",
       "4    C-D  CEKOVB2B"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['kv_key', 'key']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bizarre-pipeline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kv_key</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67658</th>\n",
       "      <td>W-X</td>\n",
       "      <td>WYAADLZL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67659</th>\n",
       "      <td>C-D</td>\n",
       "      <td>DMEFRUZM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67660</th>\n",
       "      <td>E-F</td>\n",
       "      <td>FRUDMEZM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67661</th>\n",
       "      <td>E-F</td>\n",
       "      <td>FRUOSSZM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67662</th>\n",
       "      <td>O-P</td>\n",
       "      <td>OSSFRUZM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      kv_key       key\n",
       "67658    W-X  WYAADLZL\n",
       "67659    C-D  DMEFRUZM\n",
       "67660    E-F  FRUDMEZM\n",
       "67661    E-F  FRUOSSZM\n",
       "67662    O-P  OSSFRUZM"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['kv_key', 'key']].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "minor-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition dataset\n",
    "df.to_parquet(results_dir.joinpath('kv'), partition_cols = ['kv_key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-reconstruction",
   "metadata": {},
   "source": [
    "### b."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-diving",
   "metadata": {},
   "source": [
    "We are going to partition the dataset again, but this time we will partition by the hash value of the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "parallel-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that will create a SHA256 hash of the input key and return a hexadecimal string representation of the hash.\n",
    "import hashlib\n",
    "\n",
    "def hash_key(key):\n",
    "    m = hashlib.sha256()\n",
    "    m.update(str(key).encode('utf-8'))\n",
    "    \n",
    "    return m.hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-investigation",
   "metadata": {},
   "source": [
    "We will partition the data using the first character of the hexadecimal hash. As such, there are 16 possible partitions. Create a new column called hashed that is a hashed value of the key column. Next, create a partitioned dataset based on the first character of the hashed key and save the results to results/hash. The directory should contain the following folders.\n",
    "\n",
    "hash<br />\n",
    "├── hash_key=0<br />\n",
    "├── hash_key=1<br />\n",
    "├── hash_key=2<br />\n",
    "├── hash_key=3<br />\n",
    "├── hash_key=4<br />\n",
    "├── hash_key=5<br />\n",
    "├── hash_key=6<br />\n",
    "├── hash_key=7<br />\n",
    "├── hash_key=8<br />\n",
    "├── hash_key=9<br />\n",
    "├── hash_key=A<br />\n",
    "├── hash_key=B<br />\n",
    "├── hash_key=C<br />\n",
    "├── hash_key=D<br />\n",
    "├── hash_key=E<br />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "representative-senegal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>hashed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AERKZN2B</td>\n",
       "      <td>652cdec02010381f175efe499e070c8cbaac1522bac59a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASFKZN2B</td>\n",
       "      <td>9eea5dd88177f8d835b2bb9cb27fb01268122b635b241a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASFMRV2B</td>\n",
       "      <td>161143856af25bd4475f62c80c19f68936a139f653c1d3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CEKKZN2B</td>\n",
       "      <td>39aa99e6ae2757341bede9584473906ef1089e30820c90...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CEKOVB2B</td>\n",
       "      <td>143b3389bce68eea3a13ac26a9c76c1fa583ec2bd26ea8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        key                                             hashed\n",
       "0  AERKZN2B  652cdec02010381f175efe499e070c8cbaac1522bac59a...\n",
       "1  ASFKZN2B  9eea5dd88177f8d835b2bb9cb27fb01268122b635b241a...\n",
       "2  ASFMRV2B  161143856af25bd4475f62c80c19f68936a139f653c1d3...\n",
       "3  CEKKZN2B  39aa99e6ae2757341bede9584473906ef1089e30820c90...\n",
       "4  CEKOVB2B  143b3389bce68eea3a13ac26a9c76c1fa583ec2bd26ea8..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add hash column to df\n",
    "df['hashed'] = df['key'].apply(hash_key)\n",
    "\n",
    "df[['key', 'hashed']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "signed-relation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>hash_key</th>\n",
       "      <th>hashed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AERKZN2B</td>\n",
       "      <td>6</td>\n",
       "      <td>652cdec02010381f175efe499e070c8cbaac1522bac59a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASFKZN2B</td>\n",
       "      <td>9</td>\n",
       "      <td>9eea5dd88177f8d835b2bb9cb27fb01268122b635b241a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASFMRV2B</td>\n",
       "      <td>1</td>\n",
       "      <td>161143856af25bd4475f62c80c19f68936a139f653c1d3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CEKKZN2B</td>\n",
       "      <td>3</td>\n",
       "      <td>39aa99e6ae2757341bede9584473906ef1089e30820c90...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CEKOVB2B</td>\n",
       "      <td>1</td>\n",
       "      <td>143b3389bce68eea3a13ac26a9c76c1fa583ec2bd26ea8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        key hash_key                                             hashed\n",
       "0  AERKZN2B        6  652cdec02010381f175efe499e070c8cbaac1522bac59a...\n",
       "1  ASFKZN2B        9  9eea5dd88177f8d835b2bb9cb27fb01268122b635b241a...\n",
       "2  ASFMRV2B        1  161143856af25bd4475f62c80c19f68936a139f653c1d3...\n",
       "3  CEKKZN2B        3  39aa99e6ae2757341bede9584473906ef1089e30820c90...\n",
       "4  CEKOVB2B        1  143b3389bce68eea3a13ac26a9c76c1fa583ec2bd26ea8..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add hash key column to df\n",
    "df['hash_key'] = df['hashed'].str[0]\n",
    "\n",
    "df[['key', 'hash_key', 'hashed']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "impaired-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition dataset using hk_hash\n",
    "df.to_parquet(results_dir.joinpath('hash'), partition_cols=['hash_key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-pipeline",
   "metadata": {},
   "source": [
    "### c."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-saturday",
   "metadata": {},
   "source": [
    "We will simulate multiple geographically distributed data centers. For this example, we will assume we have three data centers located in the western, central, and eastern United States. Google lists the locations of their data centers and we will use the following locations for our three data centers.\n",
    "\n",
    "##### West\n",
    "- The Dalles, Oregon\n",
    "- Latitude: 45.5945645\n",
    "- Longitude: -121.1786823\n",
    "\n",
    "##### Central\n",
    "- Papillion, NE\n",
    "- Latitude: 41.1544433\n",
    "- Longitude: -96.0422378\n",
    "\n",
    "##### East\n",
    "- Loudoun County, Virginia\n",
    "- Latitude: 39.08344\n",
    "- Longitude: -77.6497145"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-partnership",
   "metadata": {},
   "source": [
    "Assume that you have an application that provides routes for each of the source airports and you want to store routes in the data center closest to the source airport. The output folders should look as follows.\n",
    "\n",
    "geo<br />\n",
    "├── location=central<br />\n",
    "├── location=east<br />\n",
    "└── location=west<br />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "occupied-uncertainty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_airport_latitude</th>\n",
       "      <th>src_airport_longitude</th>\n",
       "      <th>airport_geohash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.449902</td>\n",
       "      <td>39.956600</td>\n",
       "      <td>szsrjjzd02b3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.283298</td>\n",
       "      <td>48.006302</td>\n",
       "      <td>v04pk3t5gbjj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.283298</td>\n",
       "      <td>48.006302</td>\n",
       "      <td>v04pk3t5gbjj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.305801</td>\n",
       "      <td>61.503300</td>\n",
       "      <td>v3gdxs17du83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.305801</td>\n",
       "      <td>61.503300</td>\n",
       "      <td>v3gdxs17du83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   src_airport_latitude  src_airport_longitude airport_geohash\n",
       "0             43.449902              39.956600    szsrjjzd02b3\n",
       "1             46.283298              48.006302    v04pk3t5gbjj\n",
       "2             46.283298              48.006302    v04pk3t5gbjj\n",
       "3             55.305801              61.503300    v3gdxs17du83\n",
       "4             55.305801              61.503300    v3gdxs17du83"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add geohash key to df\n",
    "df['airport_geohash'] = df.apply(lambda x: pygeohash.encode(x['src_airport_latitude'], \n",
    "                                                            x['src_airport_longitude']), \n",
    "                                 axis = 1)\n",
    "\n",
    "df[['src_airport_latitude', 'src_airport_longitude', 'airport_geohash']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "careful-socket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'west': 'c21g6s0rs4c7', 'central': '9z7dnebnj8kb', 'east': 'dqby34cjw922'}\n"
     ]
    }
   ],
   "source": [
    "# Get geohash location info for data centers\n",
    "data_centers = dict(\n",
    "    west = pygeohash.encode(45.5945645, -121.1786823),\n",
    "    central = pygeohash.encode(41.1544433, -96.0422378),\n",
    "    east = pygeohash.encode(39.08344, -77.6497145)\n",
    ")\n",
    "\n",
    "print(data_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "strange-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the closest datacenter from the source airport\n",
    "def get_datacenter_location(geohash): \n",
    "    distance_dict = {}\n",
    "    \n",
    "    for key in data_centers.keys():\n",
    "        distance_dict[key] = pygeohash.geohash_haversine_distance(data_centers.get(key), geohash)\n",
    "        \n",
    "    sorted_distance = sorted(distance_dict.items(), key = lambda x: x[1])[0][0]\n",
    "        \n",
    "    return sorted_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "romance-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column for closest data center\n",
    "df['data_center'] = df['airport_geohash'].apply(lambda x: get_datacenter_location(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "historic-bunch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_airport_latitude</th>\n",
       "      <th>src_airport_longitude</th>\n",
       "      <th>airport_geohash</th>\n",
       "      <th>data_center</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.449902</td>\n",
       "      <td>39.956600</td>\n",
       "      <td>szsrjjzd02b3</td>\n",
       "      <td>east</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.283298</td>\n",
       "      <td>48.006302</td>\n",
       "      <td>v04pk3t5gbjj</td>\n",
       "      <td>east</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.283298</td>\n",
       "      <td>48.006302</td>\n",
       "      <td>v04pk3t5gbjj</td>\n",
       "      <td>east</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.305801</td>\n",
       "      <td>61.503300</td>\n",
       "      <td>v3gdxs17du83</td>\n",
       "      <td>west</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.305801</td>\n",
       "      <td>61.503300</td>\n",
       "      <td>v3gdxs17du83</td>\n",
       "      <td>west</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   src_airport_latitude  src_airport_longitude airport_geohash data_center\n",
       "0             43.449902              39.956600    szsrjjzd02b3        east\n",
       "1             46.283298              48.006302    v04pk3t5gbjj        east\n",
       "2             46.283298              48.006302    v04pk3t5gbjj        east\n",
       "3             55.305801              61.503300    v3gdxs17du83        west\n",
       "4             55.305801              61.503300    v3gdxs17du83        west"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['src_airport_latitude', 'src_airport_longitude', 'airport_geohash', 'data_center']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "frozen-calibration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_airport_latitude</th>\n",
       "      <th>src_airport_longitude</th>\n",
       "      <th>airport_geohash</th>\n",
       "      <th>data_center</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67658</th>\n",
       "      <td>-33.058899</td>\n",
       "      <td>137.514008</td>\n",
       "      <td>r41gcjy9uwef</td>\n",
       "      <td>west</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67659</th>\n",
       "      <td>55.408798</td>\n",
       "      <td>37.906300</td>\n",
       "      <td>ucfgnwfe8u9e</td>\n",
       "      <td>east</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67660</th>\n",
       "      <td>43.061298</td>\n",
       "      <td>74.477600</td>\n",
       "      <td>txsuyz0fjzgd</td>\n",
       "      <td>west</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67661</th>\n",
       "      <td>43.061298</td>\n",
       "      <td>74.477600</td>\n",
       "      <td>txsuyz0fjzgd</td>\n",
       "      <td>west</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67662</th>\n",
       "      <td>40.609001</td>\n",
       "      <td>72.793297</td>\n",
       "      <td>tx5z02wkwf2p</td>\n",
       "      <td>west</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       src_airport_latitude  src_airport_longitude airport_geohash data_center\n",
       "67658            -33.058899             137.514008    r41gcjy9uwef        west\n",
       "67659             55.408798              37.906300    ucfgnwfe8u9e        east\n",
       "67660             43.061298              74.477600    txsuyz0fjzgd        west\n",
       "67661             43.061298              74.477600    txsuyz0fjzgd        west\n",
       "67662             40.609001              72.793297    tx5z02wkwf2p        west"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['src_airport_latitude', 'src_airport_longitude', 'airport_geohash', 'data_center']].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "narrative-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition dataset using closest data center location\n",
    "df.to_parquet(results_dir.joinpath('geo'), partition_cols=['data_center'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-spring",
   "metadata": {},
   "source": [
    "### d."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-occurrence",
   "metadata": {},
   "source": [
    "Create a Python function that takes as input a list of keys and the number of partitions and returns a list of keys sorted into the specified number of partitions. The partitions should be roughly equal in size. Furthermore, the partitions should have the property that each partition contains all the keys between the least key in the partition and the greatest key in the partition. In other words, the partitions should be ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "czech-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def balance_partitions(keys, num_partitions):\n",
    "    partition_size = round(len(keys) / num_partitions)\n",
    "    iterations = iter(keys)\n",
    "    \n",
    "    partitions_iterations = iter(lambda: tuple(itertools.islice(iterations, partition_size)), ())\n",
    "    \n",
    "    partitions = [sorted(part) for part in partitions_iterations]\n",
    "    \n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "whole-degree",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['4U', '7H', 'AA', 'AC', 'AY', 'DL', 'DL', 'ET', 'FL', 'QF'],\n",
       " ['AA', 'AS', 'AZ', 'JQ', 'JT', 'KY', 'O6', 'SN', 'Y4', 'nan'],\n",
       " ['3R', 'AC', 'AF', 'DL', 'GS', 'HU', 'LO', 'MU', 'U6', 'US'],\n",
       " ['8L', 'AY', 'BT', 'FR', 'NF', 'P9', 'SI', 'SN', 'VS', 'WS'],\n",
       " ['AB', 'DL', 'DL', 'FR', 'GE', 'KL', 'RJ', 'SC', 'SG', 'TK']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with sample of 50 airline rows into 5 partitions\n",
    "airline_names = df.airline_iata.sample(50).to_list()\n",
    "\n",
    "partitions = balance_partitions(airline_names, 5)\n",
    "\n",
    "partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-horse",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
